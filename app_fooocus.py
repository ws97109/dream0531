import os
import time
import subprocess
import tempfile
import uuid
import json
import logging
import sys
from flask import Flask, request, jsonify, render_template, url_for
import requests
import base64
from PIL import Image, ImageDraw, ImageFont
from io import BytesIO
import numpy as np

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app_root = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(app_root, 'static')

app = Flask(__name__, 
            template_folder=os.path.join(app_root, 'templates'),
            static_folder=static_dir)

# ==================== é…ç½®è¨­å®š ====================
# Ollama APIï¼ˆåƒ…ç”¨æ–¼æ–‡æœ¬ç”Ÿæˆï¼‰
OLLAMA_API = "http://localhost:11434/api/generate"

# æœ¬åœ°è·¯å¾‘è¨­å®š - è«‹æ ¹æ“šæ‚¨çš„å¯¦éš›æƒ…æ³ä¿®æ”¹
FOOOCUS_PATH = "/Users/lishengfeng/Desktop/æ·¡æ±Ÿèª²ç¨‹/ç”Ÿæˆå¼AI/æœŸæœ«å ±å‘Š/Fooocus"
FRAMEPACK_PATH = "/Users/lishengfeng/Desktop/æ·¡æ±Ÿèª²ç¨‹/ç”Ÿæˆå¼AI/æœŸæœ«å ±å‘Š/FramePack"

# FramePack ç›´æ¥æ•´åˆçš„å…¨å±€è®Šé‡
framepack_models_loaded = False
framepack_models = {}

# ==================== FramePack ç›´æ¥æ•´åˆ ====================

def get_device():
    """ç²å–é©åˆ Mac M4 çš„è¨­å‚™"""
    import torch
    if torch.backends.mps.is_available():
        return torch.device('mps')
    else:
        return torch.device('cpu')

def get_memory_info(device):
    """ç²å–è¨˜æ†¶é«”ä¿¡æ¯ï¼ˆMac ç‰ˆæœ¬ï¼‰"""
    if device.type == 'mps':
        # MPS æ²’æœ‰ç›´æ¥çš„è¨˜æ†¶é«”æŸ¥è©¢APIï¼Œä½¿ç”¨ä¼°ç®—å€¼
        import psutil
        available_memory = psutil.virtual_memory().available
        # è½‰æ›ç‚º GB ä¸¦ä¿å®ˆä¼°è¨ˆå¯ç”¨æ–¼ MPS çš„è¨˜æ†¶é«”
        return (available_memory / (1024 ** 3)) * 0.5  # å‡è¨­å¯ç”¨ä¸€åŠè¨˜æ†¶é«”
    else:
        # CPU æ¨¡å¼
        import psutil
        return psutil.virtual_memory().available / (1024 ** 3)

def initialize_framepack_models():
    """åˆå§‹åŒ– FramePack æ¨¡å‹ï¼ˆåƒ…åœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ™‚è¼‰å…¥ï¼‰"""
    global framepack_models_loaded, framepack_models
    
    if framepack_models_loaded:
        return True
    
    try:
        logger.info("é–‹å§‹åˆå§‹åŒ– FramePack æ¨¡å‹...")
        
        # æ·»åŠ  FramePack è·¯å¾‘åˆ° Python è·¯å¾‘
        if FRAMEPACK_PATH not in sys.path:
            sys.path.insert(0, FRAMEPACK_PATH)
        
        # è¨­å®šç’°å¢ƒè®Šé‡
        os.environ['HF_HOME'] = os.path.join(FRAMEPACK_PATH, 'hf_download')
        
        # å°å…¥å¿…è¦æ¨¡å¡Š
        import torch
        from diffusers import AutoencoderKLHunyuanVideo
        from transformers import LlamaModel, CLIPTextModel, LlamaTokenizerFast, CLIPTokenizer
        from transformers import SiglipImageProcessor, SiglipVisionModel
        
        # å°å…¥ FramePack ç‰¹å®šæ¨¡å¡Š
        from diffusers_helper.models.hunyuan_video_packed import HunyuanVideoTransformer3DModelPacked
        
        # ç²å–è¨­å‚™
        device = get_device()
        logger.info(f"ä½¿ç”¨è¨­å‚™: {device}")
        
        # æª¢æŸ¥è¨˜æ†¶é«”
        try:
            free_mem_gb = get_memory_info(device)
            high_vram = free_mem_gb > 20  # é™ä½éœ€æ±‚
            logger.info(f"å¯ç”¨è¨˜æ†¶é«”: {free_mem_gb:.2f} GB, é«˜è¨˜æ†¶é«”æ¨¡å¼: {high_vram}")
        except:
            logger.warning("ç„¡æ³•æª¢æ¸¬è¨˜æ†¶é«”ï¼Œä½¿ç”¨ CPU æ¨¡å¼")
            high_vram = False
            device = torch.device('cpu')
        
        # è¼‰å…¥æ¨¡å‹ï¼ˆä½¿ç”¨è¼ƒå°çš„è¨˜æ†¶é«”è¨­å®šï¼‰
        logger.info("è¼‰å…¥æ–‡æœ¬ç·¨ç¢¼å™¨...")
        text_encoder = LlamaModel.from_pretrained(
            "hunyuanvideo-community/HunyuanVideo", 
            subfolder='text_encoder', 
            torch_dtype=torch.float16
        ).cpu()
        
        text_encoder_2 = CLIPTextModel.from_pretrained(
            "hunyuanvideo-community/HunyuanVideo", 
            subfolder='text_encoder_2', 
            torch_dtype=torch.float16
        ).cpu()
        
        logger.info("è¼‰å…¥åˆ†è©å™¨...")
        tokenizer = LlamaTokenizerFast.from_pretrained(
            "hunyuanvideo-community/HunyuanVideo", 
            subfolder='tokenizer'
        )
        tokenizer_2 = CLIPTokenizer.from_pretrained(
            "hunyuanvideo-community/HunyuanVideo", 
            subfolder='tokenizer_2'
        )
        
        logger.info("è¼‰å…¥ VAE...")
        vae = AutoencoderKLHunyuanVideo.from_pretrained(
            "hunyuanvideo-community/HunyuanVideo", 
            subfolder='vae', 
            torch_dtype=torch.float16
        ).cpu()
        
        logger.info("è¼‰å…¥åœ–åƒç·¨ç¢¼å™¨...")
        feature_extractor = SiglipImageProcessor.from_pretrained(
            "lllyasviel/flux_redux_bfl", 
            subfolder='feature_extractor'
        )
        image_encoder = SiglipVisionModel.from_pretrained(
            "lllyasviel/flux_redux_bfl", 
            subfolder='image_encoder', 
            torch_dtype=torch.float16
        ).cpu()
        
        logger.info("è¼‰å…¥è®Šæ›å™¨...")
        transformer = HunyuanVideoTransformer3DModelPacked.from_pretrained(
            'lllyasviel/FramePackI2V_HY', 
            torch_dtype=torch.bfloat16
        ).cpu()
        
        # è¨­å®šæ¨¡å‹ç‚ºè©•ä¼°æ¨¡å¼
        vae.eval()
        text_encoder.eval()
        text_encoder_2.eval()
        image_encoder.eval()
        transformer.eval()
        
        # å•Ÿç”¨è¨˜æ†¶é«”å„ªåŒ–
        if not high_vram:
            vae.enable_slicing()
            vae.enable_tiling()
        
        # è¨­å®šé«˜è³ªé‡è¼¸å‡º
        transformer.high_quality_fp32_output_for_inference = True
        
        # ç¦ç”¨æ¢¯åº¦è¨ˆç®—
        vae.requires_grad_(False)
        text_encoder.requires_grad_(False)
        text_encoder_2.requires_grad_(False)  
        image_encoder.requires_grad_(False)
        transformer.requires_grad_(False)
        
        # ä¿å­˜æ¨¡å‹åˆ°å…¨å±€è®Šé‡
        framepack_models = {
            'text_encoder': text_encoder,
            'text_encoder_2': text_encoder_2,
            'tokenizer': tokenizer,
            'tokenizer_2': tokenizer_2,
            'vae': vae,
            'feature_extractor': feature_extractor,
            'image_encoder': image_encoder,
            'transformer': transformer,
            'high_vram': high_vram,
            'device': device
        }
        
        framepack_models_loaded = True
        logger.info("âœ… FramePack æ¨¡å‹åˆå§‹åŒ–å®Œæˆ")
        return True
        
    except ImportError as e:
        logger.error(f"âŒ FramePack æ¨¡å¡Šå°å…¥å¤±æ•—: {str(e)}")
        logger.error("è«‹ç¢ºèª FramePack ä¾è³´å·²æ­£ç¢ºå®‰è£")
        return False
    except Exception as e:
        logger.error(f"âŒ FramePack æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {str(e)}")
        return False

def generate_video_with_framepack_direct(image_path, prompt):
    """ç›´æ¥ä½¿ç”¨ FramePack æ ¸å¿ƒåŠŸèƒ½ç”Ÿæˆè¦–é »"""
    try:
        # ç¢ºä¿æ¨¡å‹å·²è¼‰å…¥
        if not initialize_framepack_models():
            logger.error("FramePack æ¨¡å‹æœªèƒ½æ­£ç¢ºåˆå§‹åŒ–")
            return None
        
        logger.info("é–‹å§‹ä½¿ç”¨ FramePack ç›´æ¥ç”Ÿæˆè¦–é »...")
        
        # å°å…¥å¿…è¦çš„è™•ç†å‡½æ•¸
        import torch
        from diffusers_helper.hunyuan import encode_prompt_conds, vae_decode, vae_encode
        from diffusers_helper.utils import save_bcthw_as_mp4, crop_or_pad_yield_mask, resize_and_center_crop, generate_timestamp
        from diffusers_helper.pipelines.k_diffusion_hunyuan import sample_hunyuan
        from diffusers_helper.clip_vision import hf_clip_vision_encode
        from diffusers_helper.bucket_tools import find_nearest_bucket
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = os.path.join(static_dir, 'videos')
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€æª”æ¡ˆå
        timestamp = int(time.time())
        random_id = str(uuid.uuid4())[:8]
        output_filename = f"dream_video_{timestamp}_{random_id}.mp4"
        output_path = os.path.join(output_dir, output_filename)
        
        # è¼‰å…¥å’Œè™•ç†è¼¸å…¥åœ–åƒ
        full_image_path = os.path.join(static_dir, image_path)
        input_image = np.array(Image.open(full_image_path))
        
        logger.info(f"è™•ç†åœ–åƒ: {input_image.shape}")
        
        # èª¿æ•´åœ–åƒå°ºå¯¸
        H, W, C = input_image.shape
        height, width = find_nearest_bucket(H, W, resolution=640)
        input_image_np = resize_and_center_crop(input_image, target_width=width, target_height=height)
        
        # è½‰æ›ç‚º PyTorch å¼µé‡
        input_image_pt = torch.from_numpy(input_image_np).float() / 127.5 - 1
        input_image_pt = input_image_pt.permute(2, 0, 1)[None, :, None]
        
        # ç²å–æ¨¡å‹å’Œè¨­å‚™
        models = framepack_models
        device = models['device']
        
        # æ–‡æœ¬ç·¨ç¢¼
        logger.info("é€²è¡Œæ–‡æœ¬ç·¨ç¢¼...")
        
        # ç§»å‹•æ–‡æœ¬ç·¨ç¢¼å™¨åˆ°è¨­å‚™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if device.type != 'cpu':
            models['text_encoder'].to(device)
            models['text_encoder_2'].to(device)
        
        llama_vec, clip_l_pooler = encode_prompt_conds(
            prompt, models['text_encoder'], models['text_encoder_2'], 
            models['tokenizer'], models['tokenizer_2']
        )
        
        # è² é¢æç¤ºè©ï¼ˆç©ºï¼‰
        llama_vec_n, clip_l_pooler_n = encode_prompt_conds(
            "", models['text_encoder'], models['text_encoder_2'], 
            models['tokenizer'], models['tokenizer_2']
        )
        
        # è™•ç†æ–‡æœ¬å‘é‡
        llama_vec, llama_attention_mask = crop_or_pad_yield_mask(llama_vec, length=512)
        llama_vec_n, llama_attention_mask_n = crop_or_pad_yield_mask(llama_vec_n, length=512)
        
        # VAE ç·¨ç¢¼
        logger.info("é€²è¡Œ VAE ç·¨ç¢¼...")
        if device.type != 'cpu':
            models['vae'].to(device)
        
        start_latent = vae_encode(input_image_pt, models['vae'])
        
        # CLIP Vision ç·¨ç¢¼
        logger.info("é€²è¡Œ CLIP Vision ç·¨ç¢¼...")
        if device.type != 'cpu':
            models['image_encoder'].to(device)
        
        image_encoder_output = hf_clip_vision_encode(
            input_image_np, models['feature_extractor'], models['image_encoder']
        )
        image_encoder_last_hidden_state = image_encoder_output.last_hidden_state
        
        # é¡å‹è½‰æ›
        transformer_dtype = models['transformer'].dtype
        llama_vec = llama_vec.to(transformer_dtype)
        llama_vec_n = llama_vec_n.to(transformer_dtype)
        clip_l_pooler = clip_l_pooler.to(transformer_dtype)
        clip_l_pooler_n = clip_l_pooler_n.to(transformer_dtype)
        image_encoder_last_hidden_state = image_encoder_last_hidden_state.to(transformer_dtype)
        
        # æ¡æ¨£åƒæ•¸ï¼ˆç°¡åŒ–ç‰ˆï¼‰
        logger.info("é–‹å§‹è¦–é »ç”Ÿæˆæ¡æ¨£...")
        
        if device.type != 'cpu':
            models['transformer'].to(device)
        
        # ç°¡åŒ–çš„æ¡æ¨£åƒæ•¸
        seed = 31337
        steps = 15  # é€²ä¸€æ­¥æ¸›å°‘æ­¥æ•¸ä»¥é©æ‡‰ Mac
        cfg = 1.0
        gs = 10.0
        rs = 0.0
        num_frames = 25  # æ¸›å°‘å¹€æ•¸ä»¥ç¯€çœè¨˜æ†¶é«”
        
        rnd = torch.Generator("cpu").manual_seed(seed)
        
        # å‰µå»ºæ¡æ¨£æ‰€éœ€çš„ç´¢å¼•å’Œæ½›åœ¨è®Šé‡
        latent_window_size = 7  # æ¸›å°‘çª—å£å¤§å°
        indices = torch.arange(0, sum([1, 0, latent_window_size, 1, 2, 16])).unsqueeze(0)
        clean_latent_indices_pre, blank_indices, latent_indices, clean_latent_indices_post, clean_latent_2x_indices, clean_latent_4x_indices = indices.split([1, 0, latent_window_size, 1, 2, 16], dim=1)
        clean_latent_indices = torch.cat([clean_latent_indices_pre, clean_latent_indices_post], dim=1)
        
        # æº–å‚™æ¸…æ½”æ½›åœ¨è®Šé‡
        clean_latents_pre = start_latent.to(device)
        clean_latents_post = torch.zeros(1, 16, 1, height // 8, width // 8, device=device, dtype=transformer_dtype)
        clean_latents_2x = torch.zeros(1, 16, 2, height // 8, width // 8, device=device, dtype=transformer_dtype)
        clean_latents_4x = torch.zeros(1, 16, 16, height // 8, width // 8, device=device, dtype=transformer_dtype)
        clean_latents = torch.cat([clean_latents_pre, clean_latents_post], dim=2)
        
        # é€²è¡Œæ¡æ¨£
        generated_latents = sample_hunyuan(
            transformer=models['transformer'],
            sampler='unipc',
            width=width,
            height=height,
            frames=num_frames,
            real_guidance_scale=cfg,
            distilled_guidance_scale=gs,
            guidance_rescale=rs,
            num_inference_steps=steps,
            generator=rnd,
            prompt_embeds=llama_vec,
            prompt_embeds_mask=llama_attention_mask,
            prompt_poolers=clip_l_pooler,
            negative_prompt_embeds=llama_vec_n,
            negative_prompt_embeds_mask=llama_attention_mask_n,
            negative_prompt_poolers=clip_l_pooler_n,
            device=device,
            dtype=transformer_dtype,
            image_embeddings=image_encoder_last_hidden_state,
            latent_indices=latent_indices,
            clean_latents=clean_latents,
            clean_latent_indices=clean_latent_indices,
            clean_latents_2x=clean_latents_2x,
            clean_latent_2x_indices=clean_latent_2x_indices,
            clean_latents_4x=clean_latents_4x,
            clean_latent_4x_indices=clean_latent_4x_indices,
            callback=None,  # ç°¡åŒ–ç‰ˆæœ¬ä¸ä½¿ç”¨å›èª¿
        )
        
        # å°‡èµ·å§‹æ½›åœ¨è®Šé‡æ·»åŠ åˆ°ç”Ÿæˆçš„æ½›åœ¨è®Šé‡
        final_latents = torch.cat([start_latent.to(generated_latents), generated_latents], dim=2)
        
        # VAE è§£ç¢¼
        logger.info("é€²è¡Œ VAE è§£ç¢¼...")
        history_pixels = vae_decode(final_latents, models['vae']).cpu()
        
        # ä¿å­˜ç‚º MP4
        logger.info(f"ä¿å­˜è¦–é »åˆ°: {output_path}")
        save_bcthw_as_mp4(history_pixels, output_path, fps=30, crf=16)
        
        # ç§»å‹•æ¨¡å‹å› CPU ä»¥ç¯€çœè¨˜æ†¶é«”
        if not models['high_vram']:
            models['text_encoder'].cpu()
            models['text_encoder_2'].cpu()
            models['vae'].cpu()
            models['image_encoder'].cpu()
            models['transformer'].cpu()
        
        logger.info("âœ… FramePack è¦–é »ç”Ÿæˆå®Œæˆ")
        return os.path.join('videos', output_filename)
        
    except ImportError as e:
        logger.error(f"FramePack æ¨¡å¡Šå°å…¥éŒ¯èª¤: {str(e)}")
        return None
    except RuntimeError as e:
        if "out of memory" in str(e).lower():
            logger.error("è¨˜æ†¶é«”ä¸è¶³ï¼Œå˜—è©¦ä½¿ç”¨è¼ƒå°çš„åƒæ•¸æˆ–é—œé–‰å…¶ä»–æ‡‰ç”¨ç¨‹å¼")
        else:
            logger.error(f"FramePack é‹è¡Œæ™‚éŒ¯èª¤: {str(e)}")
        return None
    except Exception as e:
        logger.error(f"FramePack è¦–é »ç”Ÿæˆå¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

# ==================== å…¶ä»–è¼”åŠ©å‡½æ•¸ ====================

def check_local_services():
    """æª¢æŸ¥æœ¬åœ°æœå‹™å’Œè·¯å¾‘ç‹€æ…‹"""
    try:
        # æª¢æŸ¥Ollama
        ollama_response = requests.get("http://localhost:11434/api/tags", timeout=5)
        ollama_status = ollama_response.status_code == 200
        logger.info(f"Ollama API ç‹€æ…‹: {'æ­£å¸¸' if ollama_status else 'ç•°å¸¸'}")
        
        # æª¢æŸ¥Fooocusè·¯å¾‘å’Œæ–‡ä»¶
        fooocus_status = os.path.exists(FOOOCUS_PATH)
        fooocus_executable = False
        if fooocus_status:
            fooocus_main_files = [
                os.path.join(FOOOCUS_PATH, "launch.py"),
                os.path.join(FOOOCUS_PATH, "webui.py"),
                os.path.join(FOOOCUS_PATH, "main.py"),
                os.path.join(FOOOCUS_PATH, "entry_with_update.py")
            ]
            for file_path in fooocus_main_files:
                if os.path.exists(file_path):
                    fooocus_executable = True
                    logger.info(f"æ‰¾åˆ°FooocusåŸ·è¡Œæ–‡ä»¶: {os.path.basename(file_path)}")
                    break
        
        # æª¢æŸ¥FramePackè·¯å¾‘å’Œæ ¸å¿ƒæ–‡ä»¶
        framepack_status = os.path.exists(FRAMEPACK_PATH)
        framepack_executable = False
        if framepack_status:
            framepack_main_file = os.path.join(FRAMEPACK_PATH, "demo_gradio.py")
            framepack_core_files = [
                os.path.join(FRAMEPACK_PATH, "diffusers_helper"),
                framepack_main_file
            ]
            
            if all(os.path.exists(f) for f in framepack_core_files):
                framepack_executable = True
                logger.info("æ‰¾åˆ°FramePackæ ¸å¿ƒæ–‡ä»¶: demo_gradio.py å’Œ diffusers_helper")
            else:
                logger.warning("FramePackæ–‡ä»¶ä¸å®Œæ•´")
        
        return ollama_status, fooocus_status and fooocus_executable, framepack_status and framepack_executable
    except Exception as e:
        logger.error(f"æœå‹™æª¢æŸ¥å¤±æ•—: {str(e)}")
        return False, False, False

def dream_weaver(prompt):
    """ä½¿ç”¨Ollamaçš„qwenæ¨¡å‹è™•ç†å¤¢å¢ƒæ•…äº‹ç”Ÿæˆ"""
    try:
        system_planner = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡æ•…äº‹å¤§ç¶±è¦åŠƒå°ˆå®¶ï¼Œç‰¹åˆ¥æ“…é•·åˆ†æå¤¢å¢ƒå…ƒç´ ä¸¦å‰µå»ºé€£è²«çš„æ•…äº‹æ¶æ§‹ã€‚
        ç•¶ç”¨æˆ¶æä¾›é›¶æ•£çš„å¤¢å¢ƒç‰‡æ®µæ™‚ï¼Œä½ çš„ä»»å‹™æ˜¯åˆ†ææ¯å€‹å…ƒç´ çš„è±¡å¾µæ„ç¾©ï¼Œç”¢ç”Ÿå¤šç¨®å¯èƒ½çš„æ•…äº‹æ¶æ§‹ï¼Œ
        ä¸¦æ ¹æ“šå…ƒç´ ä¹‹é–“çš„æ½›åœ¨è¯ç¹«é¸æ“‡æœ€ä½³æ¶æ§‹ã€‚è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚"""

        system_reflector = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚ä½ æ˜¯ä¸€ä½ç¹é«”ä¸­æ–‡çš„æ‰¹åˆ¤æ€§åˆ†æå°ˆå®¶ï¼Œå°ˆé–€è©•ä¼°æ•…äº‹çš„è³ªé‡å’Œé€£è²«æ€§ã€‚
        åˆ†æé€™å€‹åŸºæ–¼å¤¢å¢ƒç‰‡æ®µå‰µä½œçš„æ•…äº‹ï¼Œæ‰¾å‡ºå®ƒçš„å„ªé»å’Œä¸è¶³ä¹‹è™•ï¼Œä¸¦æä¾›å…·é«”çš„æ”¹é€²å»ºè­°ã€‚è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚"""

        system_writer = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚ä½ æ˜¯ä¸€ä½ç¹é«”ä¸­æ–‡å°ˆç²¾æ–¼å¤¢å¢ƒæ•…äº‹å‰µä½œçš„ä½œå®¶ï¼Œèƒ½å°‡é›¶æ•£çš„å¤¢å¢ƒå…ƒç´ ç·¨ç¹”æˆå¼•äººå…¥å‹çš„æ•˜äº‹ã€‚
        ä½ çš„æ•…äº‹æ‡‰è©²èåˆæ‰€æœ‰æä¾›çš„å¤¢å¢ƒå…ƒç´ ï¼Œæ•æ‰å¤¢å¢ƒç‰¹æœ‰çš„è¶…ç¾å¯¦æ€§ï¼Œä¸¦ç¬¦åˆæŒ‡å®šçš„æƒ…ç·’æ°›åœã€‚è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚"""

        # åˆ†æå¤¢å¢ƒç‰‡æ®µä¸¦è¦åŠƒæ•…äº‹å¤§ç¶±
        cot_prompt = f"""
        ä½¿ç”¨è€…æä¾›äº†ä»¥ä¸‹å¤¢å¢ƒç‰‡æ®µï¼š{prompt}

        è«‹æ€è€ƒå¦‚ä½•å°‡é€™äº›å…ƒç´ çµ„ç¹”æˆæ•…äº‹ï¼š
        1. è­˜åˆ¥æ‰€æœ‰é—œéµå…ƒç´ èˆ‡å¯èƒ½çš„è±¡å¾µæ„ç¾©
        2. è€ƒæ…®å¤šç¨®å¯èƒ½çš„æ•…äº‹æ¶æ§‹ï¼ˆè‡³å°‘ä¸‰ç¨®ï¼‰
        3. è©•ä¼°æ¯å€‹æ¶æ§‹çš„å„ªç¼ºé»
        4. é¸æ“‡æœ€ä½³æ•…äº‹å¤§ç¶±
        5. ä½¿ç”¨15-30å­—æ•¸ç¸½çµæ•…äº‹å¤§ç¶±
        6. è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†
        """

        story_outline = ollama_generate(system_planner, cot_prompt, "qwen2.5:14b")
        if not story_outline:
            return "ç„¡æ³•ç”Ÿæˆæ•…äº‹å¤§ç¶±", "ç„¡æ³•æä¾›åé¥‹", "ç„¡æ³•ç”Ÿæˆæœ€çµ‚æ•…äº‹"

        # æ•…äº‹å‰µä½œ
        story_prompt = f"""
        åŸºæ–¼ä»¥ä¸‹æ€è€ƒéç¨‹å’Œå¤§ç¶±ï¼š

        {story_outline}

        è«‹å‰µä½œä¸€å€‹å®Œæ•´çš„å¤¢å¢ƒæ•…äº‹ï¼Œèåˆæ‰€æœ‰æä¾›çš„å¤¢å¢ƒå…ƒç´ ï¼šã€Œ{prompt}ã€ã€‚
        æ•…äº‹æ‡‰å±•ç¾å¤¢å¢ƒçš„è¶…ç¾å¯¦æ€§å’Œæµå‹•æ„Ÿï¼Œé•·åº¦50-100å­—ï¼Œä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
        """

        initial_story = ollama_generate(system_writer, story_prompt, "qwen2.5:14b")
        if not initial_story:
            initial_story = "ç„¡æ³•ç”Ÿæˆåˆå§‹æ•…äº‹"

        # è©•ä¼°æ•…äº‹ä¸¦æå‡ºæ”¹é€²å»ºè­°
        reflection_prompt = f"""
        ä»¥ä¸‹æ˜¯åŸºæ–¼ç”¨æˆ¶å¤¢å¢ƒç‰‡æ®µã€Œ{prompt}ã€å‰µä½œçš„åˆæ­¥æ•…äº‹ï¼š

        {initial_story}

        è«‹è©•ä¼°é€™å€‹æ•…äº‹ä¸¦æå‡ºå…·é«”æ”¹é€²å»ºè­°ã€‚é—œæ³¨ï¼š
        1. æ˜¯å¦æ‰€æœ‰å¤¢å¢ƒå…ƒç´ éƒ½å¾—åˆ°äº†æ°ç•¶èåˆï¼Ÿ
        2. æ•…äº‹çš„è¶…ç¾å¯¦æ€§å’Œå¤¢å¢ƒæ„Ÿå¦‚ä½•ï¼Ÿ
        3. å“ªäº›éƒ¨åˆ†å¯ä»¥å¢å¼·ä»¥ä½¿æ•…äº‹æ›´åŠ å¼•äººå…¥å‹ï¼Ÿ
        4. æ•…äº‹çµæ§‹å’Œé€£è²«æ€§å¦‚ä½•ï¼Ÿ
        5. çµ¦å‡º10-25å­—æ•¸çš„ç¸½çµæ€§è©•åƒ¹å’Œå»ºè­°ã€‚
        6. ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
        """
        
        story_feedback = ollama_generate(system_reflector, reflection_prompt, "qwen2.5:14b")
        if not story_feedback:
            story_feedback = "ç„¡æ³•ç”Ÿæˆæ•…äº‹åé¥‹"

        # æ ¹æ“šåæ€å„ªåŒ–æ•…äº‹
        final_prompt = f"""
        è«‹æ ¹æ“šä»¥ä¸‹åé¥‹æ„è¦‹æ”¹é€²æ•…äº‹ï¼š

        {story_feedback}

        åŸå§‹æ•…äº‹ï¼š
        {initial_story}

        è«‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å‰µä½œæ›´åŠ å®Œå–„çš„æœ€çµ‚ç‰ˆæœ¬ï¼Œç¢ºä¿èåˆæ‰€æœ‰å¤¢å¢ƒå…ƒç´ ä¸¦å¢å¼·å…¶è¶…ç¾å¯¦æ€§ï¼Œå…¨éƒ¨éƒ½è¦ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚
        """
        
        final_story = ollama_generate(system_writer, final_prompt, "qwen2.5:14b")
        if not final_story:
            final_story = initial_story if initial_story != "ç„¡æ³•ç”Ÿæˆåˆå§‹æ•…äº‹" else "ç„¡æ³•ç”Ÿæˆæœ€çµ‚æ•…äº‹"

        return initial_story, story_feedback, final_story
    
    except Exception as e:
        logger.error(f"å¤¢å¢ƒç·¨ç¹”éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return "æ•…äº‹ç”Ÿæˆå¤±æ•—", "åé¥‹ç”Ÿæˆå¤±æ•—", "æœ€çµ‚æ•…äº‹ç”Ÿæˆå¤±æ•—"

def translate_to_english(text):
    """ä½¿ç”¨Ollamaçš„qwenæ¨¡å‹å°‡æ–‡æœ¬ç¿»è­¯æˆè‹±æ–‡"""
    try:
        if not text or text.strip() == "":
            return text

        # ç°¡å–®æª¢æŸ¥æ˜¯å¦å·²ç¶“æ˜¯è‹±æ–‡
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        if chinese_chars < len(text) * 0.3:  # å¦‚æœä¸­æ–‡å­—ç¬¦å°‘æ–¼30%ï¼Œå¯èƒ½å·²ç¶“æ˜¯è‹±æ–‡
            return text

        system_prompt = "ä½ æ˜¯ä¸€ä½ç¿»è­¯å°ˆå®¶ã€‚è«‹å°‡ç”¨æˆ¶è¼¸å…¥çš„ä»»ä½•èªè¨€ç¿»è­¯æˆè‹±æ–‡ï¼Œåªè¿”å›ç¿»è­¯çµæœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹ã€‚è«‹å°‡æè¿°è½‰æ›ç‚ºé©åˆåœ–åƒç”Ÿæˆçš„ç°¡æ½”è‹±æ–‡æç¤ºè©ã€‚"
        user_prompt = f"å°‡ä»¥ä¸‹å¤¢å¢ƒæ•…äº‹ç¿»è­¯æˆç°¡æ½”çš„è‹±æ–‡åœ–åƒæè¿°: {text}"
        
        translation = ollama_generate(system_prompt, user_prompt, "qwen2.5:14b")
        
        # å¦‚æœç¿»è­¯å¤±æ•—æˆ–å¤ªé•·ï¼Œä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬
        if not translation or len(translation) > 500:
            return "dreamlike floating scene, blue ocean, golden sunlight, surreal clouds, ethereal atmosphere"
        
        return translation
    
    except Exception as e:
        logger.error(f"ç¿»è­¯éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return "dreamlike scene, floating, ocean, sunlight, surreal atmosphere"

def generate_image_with_fooocus(prompt):
    """ä½¿ç”¨æœ¬åœ°Fooocusç”Ÿæˆåœ–åƒ - ä¿®æ­£ç‰ˆæœ¬"""
    try:
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        output_dir = os.path.join(static_dir, 'images')
        os.makedirs(output_dir, exist_ok=True)
        
        # ç”Ÿæˆå”¯ä¸€çš„æª”æ¡ˆå
        timestamp = int(time.time())
        random_id = str(uuid.uuid4())[:8]
        output_filename = f"dream_{timestamp}_{random_id}.png"
        
        # ç°¡åŒ–å’Œæ¸…ç†æç¤ºè©
        clean_prompt = prompt.replace('\n', ' ').replace('\r', ' ')[:200]  # é™åˆ¶é•·åº¦
        enhanced_prompt = f"{clean_prompt}, dreamlike, surreal, fantasy, high quality"
        
        logger.info(f"ä½¿ç”¨æœ¬åœ°Fooocusç”Ÿæˆåœ–åƒï¼Œç°¡åŒ–æç¤ºè©ï¼š{enhanced_prompt[:50]}...")
        
        # æª¢æŸ¥Fooocuså¯åŸ·è¡Œæ–‡ä»¶
        main_file = None
        fooocus_main_files = [
            os.path.join(FOOOCUS_PATH, "launch.py"),
            os.path.join(FOOOCUS_PATH, "webui.py"),
            os.path.join(FOOOCUS_PATH, "main.py"),
            os.path.join(FOOOCUS_PATH, "entry_with_update.py")
        ]
        
        for file_path in fooocus_main_files:
            if os.path.exists(file_path):
                main_file = file_path
                break
        
        if not main_file:
            logger.error("æ‰¾ä¸åˆ°Fooocusä¸»åŸ·è¡Œæ–‡ä»¶")
            return create_default_image(output_filename, prompt)
        
        # å‰µå»ºè‡¨æ™‚è¼¸å‡ºç›®éŒ„
        temp_output_dir = os.path.join(FOOOCUS_PATH, "outputs")
        os.makedirs(temp_output_dir, exist_ok=True)
        
        # æ–¹æ³•1ï¼šå˜—è©¦å•Ÿå‹•Fooocusæœå‹™ä¸¦é€šéAPIèª¿ç”¨
        try:
            # å…ˆæª¢æŸ¥æ˜¯å¦å·²ç¶“æœ‰Fooocusæœå‹™åœ¨é‹è¡Œ
            try:
                api_response = requests.get("http://localhost:7865/", timeout=2)
                if api_response.status_code == 200:
                    logger.info("æª¢æ¸¬åˆ°Fooocusæœå‹™æ­£åœ¨é‹è¡Œï¼Œå˜—è©¦APIèª¿ç”¨")
                    return generate_via_fooocus_api(enhanced_prompt, output_filename)
            except:
                pass
            
            # å¦‚æœæ²’æœ‰æœå‹™é‹è¡Œï¼Œå•Ÿå‹•Fooocusï¼ˆåƒ…å•Ÿå‹•æœå‹™ï¼Œä¸ç›´æ¥ç”Ÿæˆï¼‰
            logger.info("å•Ÿå‹•Fooocusæœå‹™...")
            fooocus_cmd = [
                sys.executable, main_file,
                "--listen", "127.0.0.1",
                "--port", "7865",
                "--output-path", temp_output_dir
            ]
            
            # åœ¨èƒŒæ™¯å•Ÿå‹•Fooocusæœå‹™
            process = subprocess.Popen(fooocus_cmd, cwd=FOOOCUS_PATH, 
                                     stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            # ç­‰å¾…æœå‹™å•Ÿå‹•ï¼ˆæœ€å¤š30ç§’ï¼‰
            for i in range(30):
                try:
                    test_response = requests.get("http://localhost:7865/", timeout=1)
                    if test_response.status_code == 200:
                        logger.info(f"Fooocusæœå‹™å•Ÿå‹•æˆåŠŸï¼ˆ{i+1}ç§’ï¼‰")
                        break
                except:
                    time.sleep(1)
            else:
                logger.warning("Fooocusæœå‹™å•Ÿå‹•è¶…æ™‚ï¼Œä½¿ç”¨é è¨­åœ–åƒ")
                process.terminate()
                return create_default_image(output_filename, prompt)
            
            # æœå‹™å•Ÿå‹•æˆåŠŸï¼Œå˜—è©¦é€šéAPIç”Ÿæˆåœ–åƒ
            result = generate_via_fooocus_api(enhanced_prompt, output_filename)
            
            # ç”Ÿæˆå®Œæˆå¾Œé—œé–‰æœå‹™
            try:
                process.terminate()
                process.wait(timeout=5)
            except:
                process.kill()
            
            return result
            
        except Exception as e:
            logger.error(f"Fooocusæœå‹™å•Ÿå‹•å¤±æ•—: {str(e)}")
            return create_default_image(output_filename, prompt)
    
    except Exception as e:
        logger.error(f"Fooocusåœ–åƒç”Ÿæˆéç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return create_default_image(f"error_{int(time.time())}.png", prompt)

def generate_via_fooocus_api(prompt, output_filename):
    """é€šéFooocus APIç”Ÿæˆåœ–åƒ"""
    try:
        api_url = "http://localhost:7865/v1/generation/text-to-image"
        
        payload = {
            "prompt": prompt,
            "negative_prompt": "blurry, low quality, deformed",
            "style_selections": ["Fooocus V2"],
            "performance_selection": "Speed",
            "aspect_ratios_selection": "1152Ã—896",
            "image_number": 1,
            "image_seed": -1,
            "sharpness": 2.0,
            "guidance_scale": 4.0,
            "base_model_name": "juggernautXL_v45.safetensors",
            "refiner_model_name": "None",
            "refiner_switch": 0.5,
            "loras": [],
            "advanced_params": {},
            "require_base64": True,
            "async_process": False
        }
        
        logger.info("ç™¼é€APIè«‹æ±‚åˆ°Fooocus...")
        response = requests.post(api_url, json=payload, timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            if result and "images" in result and len(result["images"]) > 0:
                # è§£ç¢¼base64åœ–åƒ
                image_data = result["images"][0]
                if image_data.startswith('data:image/'):
                    image_data = image_data.split(',', 1)[1]
                
                # ä¿å­˜åœ–åƒ
                output_dir = os.path.join(static_dir, 'images')
                output_path = os.path.join(output_dir, output_filename)
                
                with open(output_path, "wb") as f:
                    f.write(base64.b64decode(image_data))
                
                logger.info(f"æˆåŠŸé€šéFooocus APIç”Ÿæˆåœ–åƒ: {output_filename}")
                return os.path.join('images', output_filename)
        
        logger.error(f"Fooocus APIèª¿ç”¨å¤±æ•—: {response.status_code}")
        return create_default_image(output_filename, prompt)
        
    except Exception as e:
        logger.error(f"Fooocus APIèª¿ç”¨å‡ºéŒ¯: {str(e)}")
        return create_default_image(output_filename, prompt)

def create_default_image(filename, prompt_text=""):
    """å‰µå»ºé è¨­åœ–åƒ"""
    try:
        output_dir = os.path.join(static_dir, 'images')
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, filename)
        
        # å‰µå»ºæ¼¸è®ŠèƒŒæ™¯åœ–åƒ
        img = Image.new('RGB', (512, 512), color=(70, 130, 180))
        
        # å‰µå»ºæ¼¸è®Šæ•ˆæœ
        for y in range(512):
            for x in range(512):
                # å¾ä¸­å¿ƒå‘å¤–çš„æ¼¸è®Š
                center_x, center_y = 256, 256
                distance = ((x - center_x) ** 2 + (y - center_y) ** 2) ** 0.5
                max_distance = 256 * 1.414  # å°è§’ç·šé•·åº¦
                
                # æ ¹æ“šè·é›¢èª¿æ•´é¡è‰²
                factor = min(distance / max_distance, 1.0)
                r = int(70 + (120 - 70) * factor)
                g = int(130 + (80 - 130) * factor)
                b = int(180 + (200 - 180) * factor)
                
                img.putpixel((x, y), (r, g, b))
        
        # æ·»åŠ æ–‡å­—
        try:
            draw = ImageDraw.Draw(img)
            
            # å˜—è©¦è¼‰å…¥å­—é«”
            font_size = 32
            font = None
            
            # å˜—è©¦è¼‰å…¥å­—é«”
            font_paths = [
                # macOS
                "/System/Library/Fonts/Arial.ttf",
                "/System/Library/Fonts/Helvetica.ttc",
                "/System/Library/Fonts/PingFang.ttc",
                # Windows
                "C:/Windows/Fonts/arial.ttf",
                "C:/Windows/Fonts/calibri.ttf",
                # Linux
                "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
                "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf"
            ]
            
            for font_path in font_paths:
                try:
                    if os.path.exists(font_path):
                        font = ImageFont.truetype(font_path, font_size)
                        break
                except:
                    continue
            
            if not font:
                try:
                    font = ImageFont.load_default()
                except:
                    font = None
            
            if font:
                # ä¸»æ¨™é¡Œ
                title_text = "å¤¢å¢ƒè¦–è¦ºåŒ–"
                bbox = draw.textbbox((0, 0), title_text, font=font)
                text_width = bbox[2] - bbox[0]
                text_height = bbox[3] - bbox[1]
                x = (512 - text_width) // 2
                y = 200
                
                # æ·»åŠ æ–‡å­—é™°å½±
                draw.text((x+2, y+2), title_text, fill=(0, 0, 0, 128), font=font)
                draw.text((x, y), title_text, fill=(255, 255, 255), font=font)
                
                # åº•éƒ¨æç¤º
                info_text = "AI ç”Ÿæˆä¸­..."
                try:
                    info_font = ImageFont.truetype(font_paths[0], 18) if font_paths else font
                except:
                    info_font = font
                
                if info_font:
                    bbox = draw.textbbox((0, 0), info_text, font=info_font)
                    text_width = bbox[2] - bbox[0]
                    x = (512 - text_width) // 2
                    y = 350
                    
                    draw.text((x+1, y+1), info_text, fill=(0, 0, 0, 64), font=info_font)
                    draw.text((x, y), info_text, fill=(200, 200, 200), font=info_font)
        
        except Exception as text_error:
            logger.info(f"æ·»åŠ æ–‡å­—æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(text_error)}")
        
        img.save(output_path, 'PNG')
        logger.info(f"å‰µå»ºé è¨­åœ–åƒ: {filename}")
        return os.path.join('images', filename)
    
    except Exception as e:
        logger.error(f"å‰µå»ºé è¨­åœ–åƒå¤±æ•—: {str(e)}")
        return "images/default_dream.png"

def analyze_dream(image_path, video_path, text):
    """ä½¿ç”¨Ollamaåˆ†æå¤¢å¢ƒçš„å¿ƒç†æ„ç¾©"""
    try:
        system_prompt = """è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ã€‚ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å¤¢å¢ƒèˆ‡å¿ƒç†åˆ†æå°ˆå®¶ï¼Œæ“…é•·è§£è®€å¤¢å¢ƒçš„è±¡å¾µæ„ç¾©å’Œæ½›åœ¨çš„å¿ƒç†è¨Šæ¯ã€‚
        è«‹æ ¹æ“šä½¿ç”¨è€…æè¿°çš„å¤¢å¢ƒæä¾›æ·±å…¥çš„å¿ƒç†åˆ†æå’Œå»ºè­°ã€‚è«‹ç”¨å°ç£ç¿’æ…£çš„ä¸­æ–‡å›è¦†ï¼Œé¿å…ä½¿ç”¨éå¤šå¿ƒç†å­¸å°ˆæ¥­è¡“èªï¼Œç¢ºä¿å›ç­”é€šä¿—æ˜“æ‡‚ã€‚"""
        
        user_prompt = f"""
        ä»¥ä¸‹æ˜¯ä½¿ç”¨è€…æè¿°çš„å¤¢å¢ƒï¼š
        
        å¤¢å¢ƒæè¿°: {text}
        
        è«‹åˆ†æé€™å€‹å¤¢å¢ƒå¯èƒ½æ­ç¤ºçš„å¿ƒç†ç‹€æ…‹ã€æ½›æ„è­˜é¡˜æœ›æˆ–ææ‡¼ï¼Œä»¥åŠå¯èƒ½çš„è±¡å¾µæ„ç¾©ã€‚æä¾›å¿ƒç†å­¸è§€é»çš„è§£è®€ï¼Œ
        ä»¥åŠå°ä½¿ç”¨è€…ç•¶å‰ç”Ÿæ´»ç‹€æ…‹çš„å¯èƒ½å•Ÿç¤ºå’Œå»ºè­°ã€‚åˆ†æé•·åº¦æ§åˆ¶åœ¨150-200å­—å·¦å³ã€‚è«‹ä½¿ç”¨æº«å’Œã€æ”¯æŒæ€§çš„èªèª¿ã€‚
        """
        
        analysis = ollama_generate(system_prompt, user_prompt, "qwen2.5:14b")
        
        return analysis if analysis else "æš«æ™‚ç„¡æ³•é€²è¡Œå¿ƒç†åˆ†æï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
    
    except Exception as e:
        logger.error(f"å¤¢å¢ƒåˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        return "å¿ƒç†åˆ†æåŠŸèƒ½æš«æ™‚ä¸å¯ç”¨ï¼Œä½†æ‚¨çš„å¤¢å¢ƒæè¿°å¾ˆæœ‰è¶£ï¼Œå»ºè­°æ‚¨è¨˜éŒ„ä¸‹ä¾†ä»¥ä¾¿æ—¥å¾Œå›é¡§ã€‚"

def ollama_generate(system_prompt, user_prompt, model="qwen2.5:14b"):
    """ä½¿ç”¨Ollama APIç”Ÿæˆæ–‡æœ¬"""
    try:
        data = {
            "model": model,
            "prompt": user_prompt,
            "system": system_prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "num_predict": 500,
                "stop": ["Human:", "Assistant:", "ç”¨æˆ¶:", "åŠ©æ‰‹:"]
            }
        }
        
        logger.info(f"ç™¼é€Ollamaè«‹æ±‚ï¼Œæ¨¡å‹: {model}")
        response = requests.post(OLLAMA_API, json=data, timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            generated_text = result.get("response", "").strip()
            if generated_text:
                logger.info(f"OllamaæˆåŠŸç”Ÿæˆæ–‡æœ¬ï¼Œé•·åº¦: {len(generated_text)}")
                return generated_text
            else:
                logger.error("Ollamaè¿”å›ç©ºæ–‡æœ¬")
                return ""
        else:
            logger.error(f"Ollama APIéŒ¯èª¤: {response.status_code}, {response.text}")
            return ""
    except requests.exceptions.Timeout:
        logger.error("Ollamaè«‹æ±‚è¶…æ™‚")
        return ""
    except requests.exceptions.ConnectionError:
        logger.error("ç„¡æ³•é€£æ¥åˆ°Ollamaæœå‹™")
        return ""
    except Exception as e:
        logger.error(f"Ollamaè«‹æ±‚éŒ¯èª¤: {str(e)}")
        return ""

def save_dream_result(data):
    """ä¿å­˜å¤¢å¢ƒåˆ†æçµæœä»¥ä¾¿åˆ†äº«"""
    try:
        # å‰µå»ºå”¯ä¸€ID
        share_id = str(uuid.uuid4())
        
        # å‰µå»ºå­˜å„²ç›®éŒ„
        share_dir = os.path.join(static_dir, 'shares')
        os.makedirs(share_dir, exist_ok=True)
        
        # åŒ…å«æ™‚é–“æˆ³ä»¥æ–¹ä¾¿æ’åº
        timestamp = int(time.time())
        
        # æ§‹å»ºä¿å­˜æ•¸æ“š
        share_data = {
            'id': share_id,
            'timestamp': timestamp,
            'created_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'initialStory': data.get('initialStory', ''),
            'storyFeedback': data.get('storyFeedback', ''),
            'finalStory': data.get('finalStory', ''),
            'translation': data.get('translation', ''),
            'imagePath': data.get('imagePath', ''),
            'videoPath': data.get('videoPath', ''),
            'psychologyAnalysis': data.get('psychologyAnalysis', '')
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        share_file = os.path.join(share_dir, f"{share_id}.json")
        with open(share_file, 'w', encoding='utf-8') as f:
            json.dump(share_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ä¿å­˜åˆ†äº«æ•¸æ“šæˆåŠŸ: {share_id}")
        return share_id
    except Exception as e:
        logger.error(f"ä¿å­˜åˆ†äº«æ•¸æ“šæ™‚å‡ºéŒ¯: {str(e)}")
        return None

# ==================== è·¯ç”±å®šç¾© ====================

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/api/status')
def api_status():
    """æª¢æŸ¥æœå‹™ç‹€æ…‹"""
    ollama_status, fooocus_status, framepack_status = check_local_services()
    
    return jsonify({
        'ollama': ollama_status,
        'fooocus': fooocus_status,
        'framepack': framepack_status,
        'fooocus_path': FOOOCUS_PATH,
        'framepack_path': FRAMEPACK_PATH,
        'timestamp': int(time.time())
    })

@app.route('/api/analyze', methods=['POST'])
def analyze():
    data = request.json
    dream_text = data.get('dream', '')
    
    if not dream_text or len(dream_text.strip()) < 10:
        return jsonify({'error': 'è«‹è¼¸å…¥è‡³å°‘10å€‹å­—çš„å¤¢å¢ƒæè¿°'}), 400
    
    if len(dream_text.strip()) > 2000:
        return jsonify({'error': 'å¤¢å¢ƒæè¿°éé•·ï¼Œè«‹æ§åˆ¶åœ¨2000å­—ä»¥å…§'}), 400
    
    try:
        logger.info(f"é–‹å§‹è™•ç†å¤¢å¢ƒåˆ†æè«‹æ±‚ï¼Œè¼¸å…¥é•·åº¦: {len(dream_text)}")
        
        # æª¢æŸ¥æœå‹™ç‹€æ…‹
        ollama_status, fooocus_status, framepack_status = check_local_services()
        if not ollama_status:
            return jsonify({'error': 'Ollamaæœå‹™ä¸å¯ç”¨ï¼Œè«‹ç¢ºèªæœå‹™æ˜¯å¦æ­£å¸¸é‹è¡Œåœ¨ localhost:11434'}), 503
        
        # æ­¥é©Ÿ1: ä½¿ç”¨dream_weaverè™•ç†å¤¢å¢ƒæ•…äº‹
        logger.info("æ­¥é©Ÿ1: é–‹å§‹å¤¢å¢ƒæ•…äº‹ç”Ÿæˆ")
        initial_story, story_feedback, final_story = dream_weaver(dream_text)
        
        # æ­¥é©Ÿ2: ç¿»è­¯æ•…äº‹ä»¥ä¾¿æ›´å¥½åœ°ç”Ÿæˆåœ–åƒ
        logger.info("æ­¥é©Ÿ2: é–‹å§‹ç¿»è­¯æ•…äº‹")
        translation = translate_to_english(final_story)
        
        # æ­¥é©Ÿ3: ä½¿ç”¨æœ¬åœ°Fooocusç”Ÿæˆåœ–åƒ
        logger.info("æ­¥é©Ÿ3: é–‹å§‹ç”Ÿæˆåœ–åƒ")
        if fooocus_status:
            image_path = generate_image_with_fooocus(translation)
        else:
            logger.warning("Fooocusä¸å¯ç”¨ï¼Œä½¿ç”¨é è¨­åœ–åƒ")
            timestamp = int(time.time())
            image_path = create_default_image(f"default_{timestamp}.png", translation)
        
        # æ­¥é©Ÿ4: ä½¿ç”¨ç›´æ¥æ•´åˆçš„ FramePack ç”Ÿæˆè¦–é »
        logger.info("æ­¥é©Ÿ4: é–‹å§‹ç”Ÿæˆè¦–é »ï¼ˆç›´æ¥æ•´åˆç‰ˆï¼‰")
        video_path = None
        if framepack_status and image_path:
            video_path = generate_video_with_framepack_direct(image_path, translation)
            if video_path:
                logger.info("âœ… è¦–é »ç”ŸæˆæˆåŠŸ")
            else:
                logger.warning("âš ï¸ è¦–é »ç”Ÿæˆå¤±æ•—ï¼Œä½†ä¸å½±éŸ¿å…¶ä»–åŠŸèƒ½")
        else:
            logger.warning("FramePackä¸å¯ç”¨ï¼Œè·³éè¦–é »ç”Ÿæˆ")
        
        # æ­¥é©Ÿ5: å¿ƒç†åˆ†æ
        logger.info("æ­¥é©Ÿ5: é–‹å§‹å¿ƒç†åˆ†æ")
        psychology_analysis = analyze_dream(image_path, video_path, dream_text)
        
        # æº–å‚™éŸ¿æ‡‰
        response = {
            'initialStory': initial_story,
            'storyFeedback': story_feedback,
            'finalStory': final_story,
            'translation': translation,
            'imagePath': '/static/' + image_path if image_path else None,
            'videoPath': '/static/' + video_path if video_path else None,
            'psychologyAnalysis': psychology_analysis,
            'apiStatus': {
                'ollama': ollama_status,
                'fooocus': fooocus_status,
                'framepack': framepack_status
            },
            'processingInfo': {
                'timestamp': int(time.time()),
                'inputLength': len(dream_text),
                'storyLength': len(final_story) if final_story else 0,
                'useDirectIntegration': True
            }
        }
        
        logger.info("å¤¢å¢ƒåˆ†æå®Œæˆï¼Œæº–å‚™è¿”å›çµæœ")
        return jsonify(response)
    
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        logger.error(f"è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}\n{error_details}")
        return jsonify({
            'error': f'è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}',
            'details': error_details if app.debug else None
        }), 500

@app.route('/api/share', methods=['POST'])
def share_result():
    """å‰µå»ºå¯åˆ†äº«çš„å¤¢å¢ƒåˆ†æçµæœ"""
    data = request.json
    
    if not data or 'finalStory' not in data:
        return jsonify({'error': 'ç¼ºå°‘å¿…è¦çš„å¤¢å¢ƒåˆ†ææ•¸æ“š'}), 400
    
    try:
        # ä¿å­˜åˆ†äº«æ•¸æ“š
        share_id = save_dream_result(data)
        
        if not share_id:
            return jsonify({'error': 'å‰µå»ºåˆ†äº«å¤±æ•—'}), 500
        
        # å‰µå»ºåˆ†äº«URL
        share_url = url_for('view_shared', share_id=share_id, _external=True)
        
        return jsonify({
            'shareId': share_id, 
            'shareUrl': share_url,
            'timestamp': int(time.time())
        })
    
    except Exception as e:
        logger.error(f'è™•ç†åˆ†äº«è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        return jsonify({'error': f'è™•ç†åˆ†äº«è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}), 500

@app.route('/share/<share_id>')
def view_shared(share_id):
    """æŸ¥çœ‹åˆ†äº«çš„å¤¢å¢ƒåˆ†æçµæœ"""
    try:
        # æª¢æŸ¥åˆ†äº«IDæ ¼å¼
        if not share_id or not all(c.isalnum() or c == '-' for c in share_id):
            return jsonify({'error': 'ç„¡æ•ˆçš„åˆ†äº«ID'}), 400
        
        # è®€å–åˆ†äº«æ•¸æ“š
        share_file = os.path.join(static_dir, 'shares', f"{share_id}.json")
        
        if not os.path.exists(share_file):
            return jsonify({'error': 'æ‰¾ä¸åˆ°è©²åˆ†äº«å…§å®¹'}), 404
        
        with open(share_file, 'r', encoding='utf-8') as f:
            share_data = json.load(f)
        
        # æ¸²æŸ“åˆ†äº«é é¢
        try:
            return render_template('shared.html', data=share_data)
        except:
            return render_template('index.html', shared_data=share_data)
    
    except Exception as e:
        logger.error(f'è¼‰å…¥åˆ†äº«å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}')
        return jsonify({'error': f'è¼‰å…¥åˆ†äº«å…§å®¹æ™‚ç™¼ç”ŸéŒ¯èª¤'}), 500

@app.errorhandler(404)
def not_found_error(error):
    return jsonify({'error': 'é é¢ä¸å­˜åœ¨'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'æœå‹™å™¨å…§éƒ¨éŒ¯èª¤'}), 500

# ==================== ä¸»ç¨‹å¼å…¥å£ ====================

if __name__ == '__main__':
    try:
        # ç¢ºä¿å¿…è¦çš„ç›®éŒ„å­˜åœ¨
        directories = [
            os.path.join(static_dir, 'images'),
            os.path.join(static_dir, 'videos'),
            os.path.join(static_dir, 'shares')
        ]
        
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
            logger.info(f"ç¢ºä¿ç›®éŒ„å­˜åœ¨: {directory}")
        
        # ç¢ºä¿æœ‰é è¨­åœ–åƒ
        default_image_path = os.path.join(static_dir, 'images', 'default_dream.png')
        if not os.path.exists(default_image_path):
            try:
                logger.info("å‰µå»ºé è¨­åœ–åƒ...")
                create_default_image('default_dream.png', 'å¤¢å¢ƒç·¨ç¹”è€…ç³»çµ±')
                logger.info("é è¨­åœ–åƒå‰µå»ºæˆåŠŸ")
            except Exception as e:
                logger.error(f"ç„¡æ³•å‰µå»ºé è¨­åœ–åƒ: {str(e)}")
        
        # æª¢æŸ¥æœå‹™ç‹€æ…‹
        logger.info("æª¢æŸ¥æœå‹™ç‹€æ…‹...")
        ollama_status, fooocus_status, framepack_status = check_local_services()
        
        # è¼¸å‡ºç‹€æ…‹å ±å‘Š
        print("=" * 80)
        print("å¤¢å¢ƒç·¨ç¹”è€…ç³»çµ± - Mac M4 ç›´æ¥æ•´åˆç‰ˆæœ¬ å•Ÿå‹•ç‹€æ…‹å ±å‘Š")
        print("=" * 80)
        print(f"Ollama API (localhost:11434): {'âœ… æ­£å¸¸' if ollama_status else 'âŒ ç•°å¸¸'}")
        print(f"Fooocus è·¯å¾‘: {FOOOCUS_PATH}")
        print(f"Fooocus ç‹€æ…‹: {'âœ… å¯ç”¨' if fooocus_status else 'âŒ ä¸å¯ç”¨'}")
        print(f"FramePack è·¯å¾‘: {FRAMEPACK_PATH}")
        print(f"FramePack ç‹€æ…‹: {'âœ… å¯ç”¨ï¼ˆMPS/CPUç›´æ¥æ•´åˆï¼‰' if framepack_status else 'âŒ ä¸å¯ç”¨'}")
        print(f"éœæ…‹æª”æ¡ˆç›®éŒ„: {static_dir}")
        
        # æª¢æŸ¥ PyTorch å’Œè¨­å‚™æ”¯æŒ
        import torch
        device = get_device()
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"ä½¿ç”¨è¨­å‚™: {device}")
        if device.type == 'mps':
            print("âœ… å·²å•Ÿç”¨ Metal Performance Shaders (MPS) åŠ é€Ÿ")
        else:
            print("âš ï¸  ä½¿ç”¨ CPU æ¨¡å¼ï¼Œé€Ÿåº¦å¯èƒ½è¼ƒæ…¢")
        
        print("=" * 80)
        
        # è©³ç´°çš„ç‹€æ…‹èªªæ˜å’Œå»ºè­°
        if not ollama_status:
            print("âŒ è­¦å‘Š: Ollama API ç„¡æ³•é€£æ¥")
            print("   è«‹ç¢ºèª Ollama æœå‹™æ˜¯å¦é‹è¡Œåœ¨ localhost:11434")
            print("   å•Ÿå‹•å‘½ä»¤: ollama serve")
            print()
        
        if not fooocus_status:
            print("âŒ è­¦å‘Š: Fooocus ä¸å¯ç”¨")
            print(f"   ç•¶å‰è¨­å®šè·¯å¾‘: {FOOOCUS_PATH}")
            print("   åœ–åƒç”Ÿæˆå°‡ä½¿ç”¨é è¨­åœ–åƒ")
            print("   è«‹æª¢æŸ¥ Fooocus å®‰è£å’Œè·¯å¾‘è¨­å®š")
            print()
        
        if not framepack_status:
            print("âŒ è­¦å‘Š: FramePack ä¸å¯ç”¨ï¼ˆMPS/CPUç›´æ¥æ•´åˆæ¨¡å¼ï¼‰")
            print(f"   ç•¶å‰è¨­å®šè·¯å¾‘: {FRAMEPACK_PATH}")
            print("   è¦–é »ç”ŸæˆåŠŸèƒ½å°‡ä¸å¯ç”¨")
            print("   è«‹æª¢æŸ¥:")
            print("   1. FramePack è·¯å¾‘æ˜¯å¦æ­£ç¢º")
            print("   2. æ˜¯å¦æœ‰ demo_gradio.py å’Œ diffusers_helper ç›®éŒ„")
            print("   3. FramePack ä¾è³´æ˜¯å¦å·²å®‰è£")
            print("   4. PyTorch æ˜¯å¦æ”¯æŒ MPS æˆ– CPU æ¨¡å¼")
            print()
        
        # ç³»çµ±åŠŸèƒ½èªªæ˜
        print("ğŸ”§ ç³»çµ±åŠŸèƒ½ç‹€æ…‹:")
        print(f"   â€¢ æ•…äº‹ç”Ÿæˆ: {'âœ… å¯ç”¨ (Ollama)' if ollama_status else 'âŒ ä¸å¯ç”¨'}")
        print(f"   â€¢ æ–‡æœ¬ç¿»è­¯: {'âœ… å¯ç”¨ (Ollama)' if ollama_status else 'âŒ ä¸å¯ç”¨'}")
        print(f"   â€¢ åœ–åƒç”Ÿæˆ: {'âœ… å¯ç”¨ (æœ¬åœ°Fooocus)' if fooocus_status else 'âš ï¸  é è¨­åœ–åƒ'}")
        print(f"   â€¢ è¦–é »ç”Ÿæˆ: {'âœ… å¯ç”¨ (MPS/CPUæ•´åˆFramePack)' if framepack_status else 'âŒ ä¸å¯ç”¨'}")
        print(f"   â€¢ å¿ƒç†åˆ†æ: {'âœ… å¯ç”¨ (Ollama)' if ollama_status else 'âŒ ä¸å¯ç”¨'}")
        print()
        
        # ç‰¹æ®Šèªªæ˜
        print("ğŸš€ Mac M4 å„ªåŒ–ç‰¹æ€§:")
        if framepack_status:
            print("   â€¢ FramePack æ¨¡å‹è‡ªå‹•ä½¿ç”¨ MPS æˆ– CPU åŠ é€Ÿ")
            print("   â€¢ é‡å° Mac è¨˜æ†¶é«”é€²è¡Œå„ªåŒ–é…ç½®")
            print("   â€¢ è¦–é »ç”Ÿæˆå®Œå…¨æ•´åˆï¼Œç„¡éœ€é¡å¤–çš„ Web ç•Œé¢")
            print("   â€¢ è‡ªå‹•è¨˜æ†¶é«”ç®¡ç†å’Œè¨­å‚™å„ªåŒ–")
        print("   â€¢ æ‰€æœ‰åŠŸèƒ½é€šéçµ±ä¸€ç•Œé¢ä½¿ç”¨")
        print("   â€¢ å®Œæ•´çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„")
        print("   â€¢ é‡å° Apple Silicon é€²è¡Œå„ªåŒ–")
        print()
        
        # æœ€ä½é‹è¡Œè¦æ±‚
        if ollama_status:
            print("âœ… ç³»çµ±å¯ä»¥åŸºæœ¬é‹è¡Œï¼ˆè‡³å°‘éœ€è¦ Ollamaï¼‰")
        else:
            print("âŒ ç³»çµ±ç„¡æ³•æ­£å¸¸é‹è¡Œï¼Œéœ€è¦è‡³å°‘å®‰è£ Ollama")
        
        print("=" * 80)
        print("ç³»çµ±æº–å‚™å°±ç·’ï¼Œå•Ÿå‹• Flask æ‡‰ç”¨ç¨‹å¼...")
        print("è¨ªå•åœ°å€: http://localhost:5002")
        print("=" * 80)
        
        # å•Ÿå‹•Flaskæ‡‰ç”¨
        app.run(debug=True, host='0.0.0.0', port=5002, threaded=True)
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ¶ä¸­æ–·ï¼Œæ­£åœ¨é—œé–‰ç³»çµ±...")
    except Exception as e:
        logger.error(f"ç³»çµ±å•Ÿå‹•å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()